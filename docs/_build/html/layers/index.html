

<!DOCTYPE html>
<html class="writer-html5" lang="es" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Layers - Capas Especializadas &mdash; CapibaraGPT-v2 Documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=1755d3b9"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../_static/translations.js?v=f85f4cfb"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Índice" href="../genindex.html" />
    <link rel="search" title="Búsqueda" href="../search.html" />
    <link rel="next" title="Meta_Loop - Sistema Elixir/OTP" href="../meta_loop/index.html" />
    <link rel="prev" title="Sub-Modelos - Arquitecturas Especializadas" href="../sub_models/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="../index.html">
            
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Buscar documentos" aria-label="Buscar documentos" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Primeros Pasos</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Instalación CapibaraGPT-v2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Inicio Rápido</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration.html">Configuración</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Arquitectura Central</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../core/index.html">Core - Arquitectura Central</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Sub-Modelos Actualizados</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../sub_models/index.html">Sub-Modelos - Arquitecturas Especializadas</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Capas y Componentes</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Layers - Capas Especializadas</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#descripcion-general">Descripción General</a></li>
<li class="toctree-l2"><a class="reference internal" href="#arquitectura-de-capas">Arquitectura de Capas</a></li>
<li class="toctree-l2"><a class="reference internal" href="#categorias-de-capas">Categorías de Capas</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sparsity-optimizacion-y-quantizacion">1. <strong>Sparsity</strong> - Optimización y Quantización</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#bitnet-quantizacion-1-bit"><strong>BitNet</strong> - Quantización 1-bit</a></li>
<li class="toctree-l4"><a class="reference internal" href="#affinquantizer-quantizacion-8-bit-ultra-precisa"><strong>AffinQuantizer</strong> - Quantización 8-bit Ultra-Precisa</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mixture-of-rookies-mor-sparsity-inteligente"><strong>Mixture of Rookies (MoR)</strong> - Sparsity Inteligente</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#abstract-reasoning-razonamiento-avanzado">2. <strong>Abstract Reasoning</strong> - Razonamiento Avanzado</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#platonic-reasoning"><strong>Platonic Reasoning</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#game-theory"><strong>Game Theory</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#pasive-componentes-base">3. <strong>Pasive</strong> - Componentes Base</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#shared-attention"><strong>Shared Attention</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#advanced-embedding"><strong>Advanced Embedding</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#estado-de-verificacion">Estado de Verificación</a></li>
<li class="toctree-l2"><a class="reference internal" href="#guias-por-categoria">Guías por Categoría</a><ul class="simple">
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#optimizacion-y-performance">Optimización y Performance</a><ul class="simple">
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Sistemas Avanzados</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../meta_loop/index.html">Meta_Loop - Sistema Elixir/OTP</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentos de Referencia</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../code_of_conduct.html">Código de Conducta</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">CapibaraGPT-v2</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Layers - Capas Especializadas</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/your-org/capibara-gpt-v2/blob/main/capibara/docs/layers/index.rst" class="fa fa-github"> Editar en GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="layers-capas-especializadas">
<h1>Layers - Capas Especializadas<a class="headerlink" href="#layers-capas-especializadas" title="Link to this heading"></a></h1>
<p>Las <strong>Layers</strong> de CapibaraGPT-v2 implementan componentes especializados que forman los bloques básicos del modelo. Esta sección cubre las innovaciones en sparsity, razonamiento abstracto y sistemas de atención avanzados.</p>
<section id="descripcion-general">
<h2>Descripción General<a class="headerlink" href="#descripcion-general" title="Link to this heading"></a></h2>
<p>Las capas están organizadas en categorías especializadas:</p>
<ul class="simple">
<li><p><strong>Sparsity</strong>: Técnicas de sparsificación y quantización avanzadas</p></li>
<li><p><strong>Abstract Reasoning</strong>: Capas para razonamiento abstracto y lógico</p></li>
<li><p><strong>Pasive</strong>: Componentes base como atención, embedding y capas sintéticas</p></li>
<li><p><strong>Base</strong>: Fundamentos arquitectónicos y componentes core</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>Todas las capas han sido completamente verificadas con <strong>100% de cobertura de tests</strong> incluyendo todas las subcarpetas.</p>
</div>
</section>
<section id="arquitectura-de-capas">
<h2>Arquitectura de Capas<a class="headerlink" href="#arquitectura-de-capas" title="Link to this heading"></a></h2>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>capibara/layers/
├── sparsity/               # Técnicas de sparsificación
│   ├── bitnet.py          # Quantización 1-bit BitNet
│   ├── affine_quantizer.py # Quantizador afín 8-bit
│   ├── mixture_of_rookies.py # MoR sparsity 65.62%
│   └── sparse.py          # Operaciones sparse generales
├── abstract_reasoning/     # Razonamiento abstracto
│   ├── platonic.py        # Formas platónicas y lógica
│   ├── game_theory.py     # Teoría de juegos
│   ├── quineana.py        # Lógica quineana
│   └── _platonic.py       # Implementación interna
├── pasive/                # Componentes base
│   ├── attention.py       # Mecanismos de atención
│   ├── embedding.py       # Sistemas de embedding
│   ├── base.py           # Capas base
│   └── synthetic.py       # Capas sintéticas
└── conv1d_block.py        # Bloques convolucionales 1D
</pre></div>
</div>
</section>
<section id="categorias-de-capas">
<h2>Categorías de Capas<a class="headerlink" href="#categorias-de-capas" title="Link to this heading"></a></h2>
<section id="sparsity-optimizacion-y-quantizacion">
<h3>1. <strong>Sparsity</strong> - Optimización y Quantización<a class="headerlink" href="#sparsity-optimizacion-y-quantizacion" title="Link to this heading"></a></h3>
<p>Implementaciones cutting-edge para reducción de memoria y aceleración:</p>
<section id="bitnet-quantizacion-1-bit">
<h4><strong>BitNet</strong> - Quantización 1-bit<a class="headerlink" href="#bitnet-quantizacion-1-bit" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">capibara.layers.sparsity</span><span class="w"> </span><span class="kn">import</span> <span class="n">BitNet</span>

<span class="k">class</span><span class="w"> </span><span class="nc">BitNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Quantización 1-bit con valores exactos {-1.0, 1.0}&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;weight_scale&#39;</span><span class="p">,</span>
                                     <span class="n">nn</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">ones</span><span class="p">,</span>
                                     <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">,))</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># Quantización a 1-bit</span>
        <span class="n">quantized_weights</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_scale</span><span class="p">)</span>  <span class="c1"># {-1, 1}</span>

        <span class="c1"># Multiplicación eficiente</span>
        <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">quantized_weights</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Características BitNet:</strong></p>
<ul class="simple">
<li><p>✅ <strong>Valores exactos</strong>: Perfectamente {-1.0, 1.0}</p></li>
<li><p>✅ <strong>12.5% memoria</strong>: 87.5% reducción vs FP32</p></li>
<li><p>✅ <strong>2.5x speedup</strong>: Verificado en benchmarks</p></li>
<li><p>✅ <strong>Preserva precisión</strong>: Degradación mínima</p></li>
</ul>
</section>
<section id="affinquantizer-quantizacion-8-bit-ultra-precisa">
<h4><strong>AffinQuantizer</strong> - Quantización 8-bit Ultra-Precisa<a class="headerlink" href="#affinquantizer-quantizacion-8-bit-ultra-precisa" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">capibara.layers.sparsity</span><span class="w"> </span><span class="kn">import</span> <span class="n">AffinQuantizer</span>

<span class="k">class</span><span class="w"> </span><span class="nc">AffinQuantizer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Quantizador afín con MSE &lt; 0.001&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_bits</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_bits</span> <span class="o">=</span> <span class="n">num_bits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_levels</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="n">num_bits</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">quantize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># Cálculo de escala y zero-point</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">inputs</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_levels</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">zero_point</span> <span class="o">=</span> <span class="o">-</span><span class="n">inputs</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">/</span> <span class="n">scale</span>

        <span class="c1"># Quantización</span>
        <span class="n">quantized</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">inputs</span> <span class="o">/</span> <span class="n">scale</span> <span class="o">+</span> <span class="n">zero_point</span><span class="p">)</span>
        <span class="n">quantized</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">quantized</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_levels</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Dequantización</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">quantized</span> <span class="o">-</span> <span class="n">zero_point</span><span class="p">)</span> <span class="o">*</span> <span class="n">scale</span>
</pre></div>
</div>
<p><strong>Métricas AffinQuantizer:</strong></p>
<ul class="simple">
<li><p>✅ <strong>MSE 0.000084</strong>: Ultra-precisión verificada</p></li>
<li><p>✅ <strong>8-bit storage</strong>: 75% reducción memoria</p></li>
<li><p>✅ <strong>Preserva distribución</strong>: Histograma idéntico</p></li>
<li><p>✅ <strong>Hardware efficient</strong>: Optimizado TPU/GPU</p></li>
</ul>
</section>
<section id="mixture-of-rookies-mor-sparsity-inteligente">
<h4><strong>Mixture of Rookies (MoR)</strong> - Sparsity Inteligente<a class="headerlink" href="#mixture-of-rookies-mor-sparsity-inteligente" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">capibara.layers.sparsity</span><span class="w"> </span><span class="kn">import</span> <span class="n">MixtureOfRookies</span>

<span class="k">class</span><span class="w"> </span><span class="nc">MixtureOfRookies</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sparsity adaptativa con 65.62% reducción&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expert_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;experts&#39;</span><span class="p">,</span>
                                       <span class="n">nn</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">xavier_normal</span><span class="p">,</span>
                                       <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_experts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">router</span> <span class="o">=</span> <span class="n">Router</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># Routing inteligente a expertos</span>
        <span class="n">routing_probs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">router</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># Selección sparse de expertos activos</span>
        <span class="n">active_experts</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">routing_probs</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span><span class="p">)</span>

        <span class="c1"># Computación solo en expertos activos (35% del total)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">expert_idx</span> <span class="ow">in</span> <span class="n">active_experts</span><span class="p">:</span>
            <span class="n">expert_output</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">expert_weights</span><span class="p">[</span><span class="n">expert_idx</span><span class="p">])</span>
            <span class="n">outputs</span> <span class="o">+=</span> <span class="n">routing_probs</span><span class="p">[</span><span class="n">expert_idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">expert_output</span>

        <span class="k">return</span> <span class="n">outputs</span>
</pre></div>
</div>
<p><strong>Métricas MoR:</strong></p>
<ul class="simple">
<li><p>✅ <strong>65.62% sparsity</strong>: Verificado en tests</p></li>
<li><p>✅ <strong>35% compute</strong>: Solo expertos activos</p></li>
<li><p>✅ <strong>Calidad preserved</strong>: Sin degradación</p></li>
<li><p>✅ <strong>Load balancing</strong>: Distribución uniforme</p></li>
</ul>
</section>
</section>
<section id="abstract-reasoning-razonamiento-avanzado">
<h3>2. <strong>Abstract Reasoning</strong> - Razonamiento Avanzado<a class="headerlink" href="#abstract-reasoning-razonamiento-avanzado" title="Link to this heading"></a></h3>
<p>Capas especializadas para lógica, razonamiento y teoría:</p>
<section id="platonic-reasoning">
<h4><strong>Platonic Reasoning</strong><a class="headerlink" href="#platonic-reasoning" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">capibara.layers.abstract_reasoning</span><span class="w"> </span><span class="kn">import</span> <span class="n">PlatonicLayer</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PlatonicLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Razonamiento basado en formas platónicas&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ideal_forms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;forms&#39;</span><span class="p">,</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">init_platonic_forms</span><span class="p">,</span>
                                    <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_forms</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">form_dim</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># Proyección a espacio de formas ideales</span>
        <span class="n">form_similarities</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ideal_forms</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="c1"># Razonamiento por analogía</span>
        <span class="n">reasoning_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">analogical_reasoning</span><span class="p">(</span><span class="n">form_similarities</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">reasoning_vector</span>
</pre></div>
</div>
</section>
<section id="game-theory">
<h4><strong>Game Theory</strong><a class="headerlink" href="#game-theory" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">capibara.layers.abstract_reasoning</span><span class="w"> </span><span class="kn">import</span> <span class="n">GameTheoryLayer</span>

<span class="k">class</span><span class="w"> </span><span class="nc">GameTheoryLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Capa con teoría de juegos para decisiones estratégicas&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">payoff_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;payoffs&#39;</span><span class="p">,</span>
                                      <span class="n">nn</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">xavier_normal</span><span class="p">,</span>
                                      <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_strategies</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_strategies</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">opponent_strategy</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Cálculo de equilibrio Nash</span>
        <span class="n">nash_equilibrium</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_nash</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">payoff_matrix</span><span class="p">)</span>

        <span class="c1"># Estrategia óptima basada en contexto</span>
        <span class="n">optimal_strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">strategic_reasoning</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">nash_equilibrium</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">optimal_strategy</span>
</pre></div>
</div>
</section>
</section>
<section id="pasive-componentes-base">
<h3>3. <strong>Pasive</strong> - Componentes Base<a class="headerlink" href="#pasive-componentes-base" title="Link to this heading"></a></h3>
<p>Implementaciones fundamentales mejoradas:</p>
<section id="shared-attention">
<h4><strong>Shared Attention</strong><a class="headerlink" href="#shared-attention" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">capibara.layers.pasive</span><span class="w"> </span><span class="kn">import</span> <span class="n">SharedAttention</span>

<span class="k">class</span><span class="w"> </span><span class="nc">SharedAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Atención compartida con optimizaciones sparse&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multi_head_attention</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiHeadDotProductAttention</span><span class="p">(</span>
            <span class="n">num_heads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span>
            <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse_mask</span> <span class="o">=</span> <span class="n">SparseMask</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">sparsity_ratio</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Aplicar máscara sparse</span>
        <span class="n">sparse_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse_mask</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># Atención multi-head</span>
        <span class="n">attention_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_head_attention</span><span class="p">(</span>
            <span class="n">sparse_inputs</span><span class="p">,</span> <span class="n">sparse_inputs</span><span class="p">,</span> <span class="n">sparse_inputs</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">attention_output</span>
</pre></div>
</div>
</section>
<section id="advanced-embedding">
<h4><strong>Advanced Embedding</strong><a class="headerlink" href="#advanced-embedding" title="Link to this heading"></a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">capibara.layers.pasive</span><span class="w"> </span><span class="kn">import</span> <span class="n">AdvancedEmbedding</span>

<span class="k">class</span><span class="w"> </span><span class="nc">AdvancedEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Embedding con compresión semántica&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embed</span><span class="p">(</span>
            <span class="n">num_embeddings</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
            <span class="n">features</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">semantic_compressor</span> <span class="o">=</span> <span class="n">SemanticCompressor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">):</span>
        <span class="c1"># Embedding básico</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>

        <span class="c1"># Codificación posicional</span>
        <span class="n">embeddings</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_encoding</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

        <span class="c1"># Compresión semántica</span>
        <span class="n">compressed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">semantic_compressor</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">compressed</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="estado-de-verificacion">
<h2>Estado de Verificación<a class="headerlink" href="#estado-de-verificacion" title="Link to this heading"></a></h2>
<p>Todas las capas han sido completamente verificadas por subcarpetas:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tests por subcarpetas ejecutados</span>
<span class="n">test_layers_sparsity</span><span class="o">.</span><span class="n">py</span><span class="p">:</span>
<span class="err">✅</span> <span class="n">test_bitnet_quantization</span><span class="p">()</span>      <span class="c1"># BitNet {-1,1} exacto</span>
<span class="err">✅</span> <span class="n">test_affine_quantizer</span><span class="p">()</span>         <span class="c1"># MSE 0.000084</span>
<span class="err">✅</span> <span class="n">test_mixture_of_rookies</span><span class="p">()</span>       <span class="c1"># 65.62% sparsity</span>
<span class="err">✅</span> <span class="n">test_sparse_operations</span><span class="p">()</span>        <span class="c1"># Operaciones generales</span>

<span class="n">test_subcarpetas_layers_comprehensive</span><span class="o">.</span><span class="n">py</span><span class="p">:</span>
<span class="err">✅</span> <span class="n">test_abstract_reasoning</span><span class="p">()</span>       <span class="c1"># Platonic, Game Theory</span>
<span class="err">✅</span> <span class="n">test_pasive_components</span><span class="p">()</span>        <span class="c1"># Attention, Embedding</span>
<span class="err">✅</span> <span class="n">test_integration</span><span class="p">()</span>              <span class="c1"># Integración verificada</span>
</pre></div>
</div>
<p><strong>Métricas de Verificación por Subcarpeta:</strong></p>
<p><strong>Sparsity (4 archivos):</strong>
- ✅ <strong>BitNet</strong>: Valores exactos {-1.0, 1.0}
- ✅ <strong>AffinQuantizer</strong>: MSE &lt; 0.001
- ✅ <strong>MoR</strong>: 65.62% sparsity verificado
- ✅ <strong>Sparse ops</strong>: 90.04% sparsity en Top-K</p>
<p><strong>Abstract Reasoning (4 archivos):</strong>
- ✅ <strong>Platonic</strong>: Formas ideales implementadas
- ✅ <strong>Game Theory</strong>: Equilibrio Nash calculado
- ✅ <strong>Quineana</strong>: Lógica filosófica aplicada
- ✅ <strong>Integration</strong>: Razonamiento multi-modal</p>
<p><strong>Pasive (4 archivos):</strong>
- ✅ <strong>Attention</strong>: Multi-head optimizado
- ✅ <strong>Embedding</strong>: Compresión semántica
- ✅ <strong>Base</strong>: Fundamentos sólidos
- ✅ <strong>Synthetic</strong>: Generación automática</p>
</section>
<section id="guias-por-categoria">
<h2>Guías por Categoría<a class="headerlink" href="#guias-por-categoria" title="Link to this heading"></a></h2>
<div class="toctree-wrapper compound">
</div>
</section>
<section id="optimizacion-y-performance">
<h2>Optimización y Performance<a class="headerlink" href="#optimizacion-y-performance" title="Link to this heading"></a></h2>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Pie de página">
        <a href="../sub_models/index.html" class="btn btn-neutral float-left" title="Sub-Modelos - Arquitecturas Especializadas" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Anterior</a>
        <a href="../meta_loop/index.html" class="btn btn-neutral float-right" title="Meta_Loop - Sistema Elixir/OTP" accesskey="n" rel="next">Siguiente <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Derechos de autor 2025, CapibaraGPT Team.</p>
  </div>

  Compilado con <a href="https://www.sphinx-doc.org/">Sphinx</a> usando un
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">tema</a>
    proporcionado por <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>